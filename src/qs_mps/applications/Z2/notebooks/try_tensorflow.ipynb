{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 15:57:56.266539: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from qs_mps.mps_class import MPS\n",
    "from qs_mps.utils import get_precision, tensor_shapes\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_i = 2\n",
    "h_f = 6\n",
    "npoints = 20\n",
    "interval = np.linspace(h_i,h_f,npoints)\n",
    "num = (h_f - h_i) / npoints\n",
    "precision = get_precision(num)\n",
    "L=6\n",
    "l=5\n",
    "d=2**l\n",
    "model=\"Z2_dual\"\n",
    "chi=64\n",
    "charges_x = None\n",
    "charges_y = None\n",
    "path_tensor = \"/Users/fradm98/Desktop/projects/1_Z2\"\n",
    "# for h in interval:\n",
    "h = 2.0\n",
    "lattice_mps = MPS(L=L, d=d, model=model, chi=chi, h=h)\n",
    "lattice_mps.L = lattice_mps.L - 1\n",
    "\n",
    "lattice_mps.load_sites(path=path_tensor, precision=precision, cx=charges_x, cy=charges_y)\n",
    "lattice_mps.Z2.mpo_Z2_ladder_generalized()\n",
    "lattice_mps.w = lattice_mps.Z2.mpo.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32)\n",
      "(32, 32, 64)\n",
      "(64, 32, 64)\n",
      "(64, 32, 32)\n",
      "(32, 32, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 32, 32), (32, 32, 64), (64, 32, 64), (64, 32, 32), (32, 32, 1)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_shapes(lattice_mps.sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ncon import ncon\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contration with `ncon`\n",
    "\n",
    "We execute the contraction, with the function `ncon`, of the environments to get the $H_{eff}$.  \n",
    "Subsequently, we reshape the tensor for the diagonalization of the effective matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "9.61 s ± 134 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "(32, 32, 32, 32, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1]) \n",
    "v_l = np.zeros((lattice_mps.w[0].shape[0]))\n",
    "v_l[0] = 1\n",
    "env_l = ncon([a,v_l,a],[[-1],[-2],[-3]])\n",
    "env_l = ncon([env_l, lattice_mps.sites[0], lattice_mps.w[0], lattice_mps.sites[0].conjugate()],[[1,2,3],[1,4,-1],[2,-2,4,5],[3,5,-3]])\n",
    "v_r = np.zeros((lattice_mps.w[-1].shape[1]))\n",
    "v_r[-1] = 1\n",
    "env_r = ncon([a,v_r.T,a],[[-1],[-2],[-3]])\n",
    "env_r = ncon([env_r, lattice_mps.sites[-1], lattice_mps.w[-1], lattice_mps.sites[-1].conjugate()],[[1,2,3],[-1,4,1],[-2,2,4,5],[-3,5,3]])\n",
    "print(\"Here\")\n",
    "arr = ncon([env_l,lattice_mps.w[1],env_r],[[-1,1,-4],[1,2,-2,-5],[-3,2,-6]])\n",
    "%timeit ncon([env_l,lattice_mps.w[1],env_r],[[-1,1,-4],[1,2,-2,-5],[-3,2,-6]])\n",
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.1 s ± 118 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# reshape\n",
    "%timeit arr.reshape((2**15,2**15))\n",
    "arr_resh = arr.reshape((2**15,2**15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show a total time of $22.41 s$ for contraction and reshaping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contraction with `tf.tensordot()`\n",
    "\n",
    "The same contraction and reshaping can be executed by converting the `numpy.ndarray`s in `tensorflow`'s objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 7, 32, 32) (32, 7, 32) (32, 7, 32)\n"
     ]
    }
   ],
   "source": [
    "mpo_mid = tf.constant(lattice_mps.w[1])\n",
    "env_l = tf.constant(env_l)\n",
    "env_r = tf.constant(env_r)\n",
    "print(mpo_mid.get_shape(), env_l.get_shape(), env_r.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.56 s ± 39.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "env = tf.tensordot(env_l,mpo_mid,[[1],[0]])\n",
    "%timeit tf.tensordot(env,env_r,[[2],[1]])\n",
    "env = tf.tensordot(env,env_r,[[2],[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.5 µs ± 435 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
      "(32768, 32768)\n"
     ]
    }
   ],
   "source": [
    "%timeit env_new = tf.reshape(env, (2**15,2**15))\n",
    "env_new = tf.reshape(env, (2**15,2**15))\n",
    "print(env_new.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32768, 32768)\n",
      "8.63 s ± 92.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(env_new.get_shape())\n",
    "%timeit b = env_new.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total time of contraction and reshaping is faster by a factor $\\text{x}6$. The only problem is that to execute the diagonalization, we need to get back the `numpy.ndarray` and perform the sparse operation `eigsh`. This conversion takes $8.63s$, the advantage is still present in the case we use tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.9 s ± 265 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "28.1 s ± 2.58 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.linalg import eigsh\n",
    "%timeit e,v = eigsh(env_new.numpy(), k=1, which=\"SA\")\n",
    "%timeit e,v = eigsh(arr_resh, k=1, which=\"SA\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
